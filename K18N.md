# KUBERNETES DOCUMENTATIONS

  <-- disable swapoff -->

    sudo apt  update && sudo apt upgrade -y

    sudo swapoff -a

  <-- getting pre-install library -->

    curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

    echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

    sudo apt update 

 
    sudo apt install docker.io kubelet kubeadm kubectl kubernetes-cni -y 


    sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=23.217.135.42


kubeadm join 23.217.135.42:6443 --token 68jaei.6r4pk2ryhbz2zvft \
        --discovery-token-ca-cert-hash sha256:6e40afec254c857a1801fc4d48f9ed73727314537e14499c4fbb84e8b5109213



    mkdir -p $HOME/.kube
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config

    Alternatively, if you are the root user, you can run:

    export KUBECONFIG=/etc/kubernetes/admin.conf

    nodename=$(kubectl get node -o jsonpath='{.items[0].metadata.name}')
    kubectl taint node $nodename node-role.kubernetes.io/master:NoSchedule-
    kubectl label --overwrite node $nodename ovn4nfv-k8s-plugin=ovn-control-plane

    kubectl apply -f https://raw.githubusercontent.com/opnfv/ovn4nfv-k8s-plugin/master/deploy/ovn-daemonset.yaml
    kubectl apply -f https://raw.githubusercontent.com/opnfv/ovn4nfv-k8s-plugin/master/deploy/ovn4nfv-k8s-plugin.yaml

    <--create cluster role binding to access apiserver from outside-->

    kubectl create clusterrolebinding cluster-system-anonymous --clusterrole=cluster-admin --user=system:anonymous

    kubectl get cs --> check component status

    if it is not healthy for scheduler and control-manager

    sudo nano /etc/kubernetes/manifests/kube-scheduler.yaml
     
     comment this line -port 0

    sudo nano /etc/kubernetes/manifests/kube-controller-manager.yaml
     
     comment this line -port 0

    systemctl restart kubelet.service

    <--check component status again-->

    kubectl get cs

    <--deploy dashboard -->
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml

    <--Access Web-ui-->
    kubectl proxy --address=0.0.0.0 --accept-hosts='.*'




    check if proxy wroking from browser http://23.217.135.42:8001/

    check if dashboard working from browser 

    /api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/

    http://23.217.135.42:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/



    ssh -L localhost:8001:127.0.0.1:8001 root@23.217.135.42

    after password, it login into server... 



    https://upcloud.com/community/tutorials/deploy-kubernetes-dashboard/





    now on the browser, 

    http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login




    on the master

    kubectl get nodes

    should show ready status




https://gist.github.com/martin-magakian/c43d547b1214dacac9f7d56f1cb00128


    kubectl run guids --image=alexellis2/guid-service:latest --port 9000

    kubectl get pods

    now copy the id and use in belwo command

    kubectl describe pod guids | grep IP


    ??? kubectl describe services kubernetes-dashboard --namespace=kube-system


    curl 10.233.64.11:9000/guid

    kubectl logs guids

    kubectl exec -it guids sh
